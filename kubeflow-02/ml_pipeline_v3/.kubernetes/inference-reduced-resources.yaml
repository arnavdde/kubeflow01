spec:
  template:
    spec:
      containers:
      - name: inference
        resources:
          requests:
            cpu: "250m"
            memory: "1Gi"
          limits:
            cpu: "1000m"
            memory: "2Gi"
